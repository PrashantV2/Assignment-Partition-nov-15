{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efa10751-c81e-41f6-af50-9adc5fd1df97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "schema = StructType([\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Country\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49e1afd1-bb65-47f9-b1ff-3ba605e29113",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Name: string (nullable = true)\n |-- Age: integer (nullable = true)\n |-- Country: string (nullable = true)\n |-- City: string (nullable = true)\n\n+-------+---+-------+-----------+\n|   Name|Age|Country|       City|\n+-------+---+-------+-----------+\n|  Alice| 30| Canada|    Toronto|\n|    Bob| 25| Canada|  Vancouver|\n|Charlie| 35|    USA|   New York|\n|  David| 28|    USA|Los Angeles|\n|    Eva| 22| Canada|   Montreal|\n|  Frank| 40|    USA|    Chicago|\n+-------+---+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (\"Alice\", 30, \"Canada\", \"Toronto\"),\n",
    "    (\"Bob\", 25, \"Canada\", \"Vancouver\"),\n",
    "    (\"Charlie\", 35, \"USA\", \"New York\"),\n",
    "    (\"David\", 28, \"USA\", \"Los Angeles\"),\n",
    "    (\"Eva\", 22, \"Canada\", \"Montreal\"),\n",
    "    (\"Frank\", 40, \"USA\", \"Chicago\")\n",
    "]\n",
    "\n",
    "# Create DataFrame using the defined schema\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.printSchema()\n",
    "\n",
    "# Display the DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "728390bd-561a-4bcd-9dc5-8ad016f58299",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the DataFrame to disk partitioned by the \"Country\" column\n",
    "output_path = \"/FileStore/partitioned_data\"\n",
    "df.write.mode(\"overwrite\").partitionBy(\"Country\").parquet(output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ede60d1f-4223-4968-ba66-ed182e31af21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----------+-------+\n|   Name|Age|       City|Country|\n+-------+---+-----------+-------+\n|  David| 28|Los Angeles|    USA|\n|Charlie| 35|   New York|    USA|\n|  Alice| 30|    Toronto| Canada|\n|    Bob| 25|  Vancouver| Canada|\n|  Frank| 40|    Chicago|    USA|\n|    Eva| 22|   Montreal| Canada|\n+-------+---+-----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Read the partitioned data\n",
    "partitioned_df = spark.read.parquet(output_path)\n",
    "\n",
    "# Display the data\n",
    "partitioned_df.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Assignment Partition 15 nov",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
